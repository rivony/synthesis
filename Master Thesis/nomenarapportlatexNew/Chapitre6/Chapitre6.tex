%------------------------------début entêtes-----------------------------------------
\pagestyle{fancy}

\renewcommand{\footrulewidth}{1pt}

\fancyhead[L]{\footnotesize \rightmark}
%\fancyhead[C]{\thepage}
\fancyhead[R]{Contribution}

\fancyfoot[L]{Ny Hoavy Nomena}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{Annotation automatique d'images}

%------------------------------fin entêtes-------------------------------------------

%\section{Expérimentation} \label{experimentation}


%\subsection{Implémentation}

\section{Résultats} \label{resultat}

\subsection{résultats de la classification}
Pendant l'apprentissage du modèle de classification, nous avons suivi son évolution en visualisant l'erreur commise et la qualité de la prédiction mesurée par l'erreur de Hamming, la distance de Hamming et l' \textit{accuracy} (figure \ref{fig:evolution}). Selon ces résultats, le modèle commence à être saturé  à partir de la $80000$ ème itération, point auquel nous avons sauvegardé notre modèle final.
%. Le modèle final est alors sauvegardé avant cette saturation c'est à dire à la 80000 ème itération.\\
A partir du modèle obtenu, nous avons pu extraire le vecteur de catégories associé à une image donnée par propagation directe de cette image (redimensionnée à $224 \times 224$) sur ce modèle. A partir de la mesure \textit{exact match ratio} en moyenne, le modèle a pu prédire exactement toutes les catégories pour les $29,4\%$  des images de validation. La distance de Hamming  et l'\textit{accuracy} correspondant est à $98\%$ qui mesure la performance partielle du modèle final. Les figures \ref{fig:parfcla}, \ref{fig:partcla} et \ref{fig:noncla} nous montrent des exemples d'images parfaitement classées, partiellement classées et non-classées par le modèle.\\

\begin{figure}[ht!]
     \begin{center}
%
        \subfigure[Diminution de l'erreur commise]{%
            \label{fig:decrerror}
            \includegraphics[width=0.5\textwidth]{resclassificationloss}
        }%
        \subfigure[Accroissement de la performance du modèle mesurée par la distance de Hamming, l'erreur de Hamming et l'accuracy score]{%
           \label{fig:accperf}
           \includegraphics[width=0.6\textwidth]{resclassific}
        }
    \end{center}
    \caption{%
        Évolution de la performance du modèle de classification pendant  l'apprentissage
     }%
   \label{fig:evolution}
\end{figure}

\begin{figure}[ht!]
     \begin{center}
%
        \subfigure[images parfaitement classées]{%
            \label{fig:parfcla}
            \includegraphics[width=0.4\textwidth, height=0.4\textwidth]{resclassificationparf}
        }%
        \subfigure[images partiellement classées]{%
            \label{fig:partcla}
            \includegraphics[width=0.4\textwidth, height=0.4\textwidth]{resclassificationpart}
        }%
        \\ %  ------- End of the first row ----------------------%
        \subfigure[image non-classée]{%
            \label{fig:noncla}
            \includegraphics[width=0.4\textwidth]{resclassificationzero}
        }%
%
    \end{center}
    \caption{%
        Exemples d'images classées par le modèle
     }%
   \label{fig:exclassif}
\end{figure}

\subsection{résultats de la génération de descriptions}

Les modèles de génération de descriptions ont été comparés au fur et à mesure de leur apprentissage. Pour chaque modèle, les mesures de performance: BLEU-1, BLEU-4, METEOR et CIDEr ont été calculés à chaque 10000 itérations sur les images de test pour évaluer l'évolution des modèles.

D'après les résultats, illustrés par la figure \ref{fig:rescapt}, on remarque que pour toutes les  mesures les courbes de notre modèle (en rouge \includegraphics[scale=0.4]{point}) sont constamment au-dessus des courbes du modèle de base (en vert \includegraphics[scale=0.4]{pointV}). Ceci confirme l'amélioration apportée par notre contribution sur le modèle de base. 

Notre modèle a une performance sensiblement similaire à celle du 
"model-init"
%modèle inspiré de show and tell  \cite{vinyals2015show} et deep visual aligment \cite{karpathy2015deep}  
(courbes en bleu \includegraphics[scale=0.4]{pointB}) après 40000 itérations. 

Les courbes jaunes \includegraphics[scale=0.4]{pointJ} représentent la performance du modèle optimal de notre contribution et on remarque une nette amélioration de la performance dans ce cas.


\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.95\textwidth]{resultcomparecorr}
		\caption{Evolution des mesures BLEU-1, BLEU-4, METEOR et CIDEr lors de l'apprentissage des quatre modèles}	
		\label{fig:rescapt}
	\end{center}
	Pour toutes les mesures, les modèles ayant des scores élevés sont les meilleurs
\end{figure}

Le tableau \ref{tab:resdesc} montre des exemples de phrases générées à partir de notre modèle. Nous avons pris les meilleures phrases générées par notre modèle et les phrases de la collection similaire à ces dernières.

\begin{table}
\resizebox{\textwidth}{!}{
\tiny
\begin{tabular}{M{4cm} M{4cm} M{4cm} M{4cm}}
a close up of a street sign near many trees & 
a toilet with plants growing from the bowl&  
a kitchen with a table, sink, microwave and plates& 
two pizzas are sitting in boxes each {\color{red}with a slice missing} \cr
\textbf{a {\color{red} red stop sing} sitting in front of a tree}& 
\textbf{a white toilet {\color{red} sitting in the middle of a field}}&  
\textbf{a kitchen with a sink and a {\color{red}refrigerator}}& 
\textbf{two pizzas sitting on top of a table} \cr
\includegraphics[width=0.2\textwidth, height=0.25\textwidth]{226128} & 
\includegraphics[width=0.2\textwidth, height=0.25\textwidth]{410670}& 
\includegraphics[width=0.2\textwidth, height=0.25\textwidth]{203661} &
\includegraphics[width=0.2\textwidth, height=0.25\textwidth]{156100}\cr \cr
black and white photo of posters and bikes on a brick wall& 
a large glass of wine is next to the bottle&  
a dog running {\color{red}across a field} with a frisbee in it's mouth& 
little girl sitting on a bed looking at a laptop  \cr
\textbf{a black and white photo of {\color{red}a park bench}}& 
\textbf{a bottle of wine and {\color{red}a bottle of wine}}&  
\textbf{a dog running with a frisbee in its mouth}& 
\textbf{a {\color{red}woman} sitting on a bed {\color{red}using} a laptop computer} \cr
\includegraphics[width=0.2\textwidth, height=0.21\textwidth]{219589} & 
\includegraphics[width=0.2\textwidth, height=0.21\textwidth]{500492}& 
\includegraphics[width=0.2\textwidth, height=0.21\textwidth]{256657} &
\includegraphics[width=0.2\textwidth, height=0.21\textwidth]{51610}
%text gt 9& 
%text gt 10&  
%text gt 11& 
%text gt 12 \\
%\includegraphics[width=0.5\textwidth]{rescaptcompare1} & \includegraphics[width=0.5\textwidth]{resclassificationzero} & \includegraphics[width=0.5\textwidth]{resclassificationzero} & \includegraphics[width=0.5\textwidth]{resclassificationzero} 
\end{tabular}
}
\smallskip
Les descriptions en gras sont les descriptions générées à partir de notre modèle.\\
Les mots ou suites de mots en rouge indiquent les erreurs ou les concepts manquants dans les descriptions générées.
\label{tab:resdesc}
\caption{Exemples de descriptions générées }
\end{table}

%\begin{table}
%\caption{Resultat des modèles de l'état de l'art sur le test set}
%\begin{tabular}{|M{4cm}|c|c|c|c|c|c|c|}
%    \hline
%    modèles & B-1 & B-2 & B-3 & B-4 & METEOR & CIDEr & ROUGEL \\
%	\hline
%    BRNN Karpathy et al. & 62.5 & 45.0 & 32.1 & 23.0 & 19.5 & 66.0 & - \\ 	
%	\hline
%    NIC Google & - & - & - & 27.7 & 23.7 & 85.5 & -  \\    
%    \hline
%    m-RNN 1 & 0.680 & 0.506 & 0.369 & 0.272 & 0.225 & 0.791 & 0.499  \\
%    \hline
%    m-RNN 2 & 0.685 & 0.512 & 0.376 & 0.279 & 0.229 & 0.819 & 0.504  \\
%    \hline
%    m-RNN Vcat +1 -1  & - & - & - & - & - & - & -  \\
%    \hline
%    notre modèle & - & - & - & - & - & - & - \\
%    \hline  
%\end{tabular}
%\end{table}
