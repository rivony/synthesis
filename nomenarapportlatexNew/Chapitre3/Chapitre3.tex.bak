%------------------------------début entêtes-----------------------------------------
\pagestyle{fancy}

\renewcommand{\footrulewidth}{1pt}

\fancyhead[L]{\footnotesize \rightmark}
\fancyhead[C]{\thepage}
\fancyhead[R]{Extraction des termes candidats}

\fancyfoot[L]{Ramiandrisoa Faneva}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{Extraction d'information}

%------------------------------fin entêtes-------------------------------------------

\chapter{Extraction des termes candidats}
\qquad Le but d'une extraction des termes candidats est la détermination des unités textuelles pouvant potentiellement être des termes-clés, c’est-à-dire les unités textuelles possédant des particularités similaires à celles des termes-clés définis par des humains. Nous savons par exemple que la majorité des mots constituant les termes-clés sont des noms et des adjectifs. Cette étape de sélection des termes candidat offre deux avantages : l'une est la réduction du temps de calcul lors de l’extraction des mots clés, et l'autre est la suppression des unités textuelles non pertinentes.

\section{N-grammes}
\qquad Les n-grammes sont toutes les séquences ordonnées de n mots adjacents. Leur extraction est très exhaustive, elle propose un nombre élevé de termes candidats que ce soit des termes candidats pertinent (plus vraissemblable de devinir des mots clés) ou non. Afin de résoudre en partie le problème des termes candidat non pertinents, l’utilisation d'un anti-dictionnaire afin de filtrer les candidats est très courant. Ce dernier regroupe tou les mots courants (« presque », « près », «  plusieurs », …) et les mots fonctionnels de la langue (prépositions, conjonctions, …) . Un n-gramme présentant, soit en début soit en fin, un des mots présents dans l’anti-dictionnaire ne sera pas ainsi séléctionné pour être un terme candidat. Malgré son aspect très bruité, l’extraction n-gramme est encore l'une des méthodes les plus utilisées parmi les méthodes supervisées (Witten et al., 1999 ; Turney, 2000 ; Hulth, 2003). La phase d’apprentissage de ce dernier les rend moins sensibles aux éventuels bruit.

\smallskip

\textbf{\textit{Exemple :}} les $\lbrace$1 $\cdots$ 3$\rbrace$-grammes sélectionnés dans la phrase « Une légère brise de côte pourra faiblement rafraichir l’atmosphère » donnent : « légère », « brise », « côte », « pourra », « faiblement », « rafraichir », « atmosphère », « légère brise », « côte pourra », « pourra faiblement », « faiblement rafraichir », « brise de côte », « côte pourra faiblement », « pourra faiblement rafraichir » et enfin « rafraichir l’atmosphère ».

\section{Chunks nominaux}
\qquad Ce sont des syntagmes non récursifs tel que la tête est un nom suivi de ses éventuels déterminants et modifieurs usuels. Ils sont linguistiquement définis, c'est à dire qu'ils sont plus fiables que les n-grammes, comme le prouvent les expériences réalisées par Hulth (2003), Eichler et Neumann (2010). En dépis de cela, Hulth (2003) remarque que l’utilisation de l’étiquetage grammatical des termes candidats durant de l’extraction supervisée de termes-clés offre la possibilité d’éliminer les n-grammes incorrects (grammaticalement) et d’obtenir de meilleurs performances qu’avec les chunks nominaux.

\smallskip

\textbf{\textit{Exemple :}} les chunks nominaux sélectionnés dans la phrase « Une légère brise de côte pourra faiblement rafraichir l’atmosphère » sont : « une légère brise », « côte » et « l’atmosphère ».

\section{Sélection de mots à partir de patrons grammaticaux prédéfinis}
\qquad Cette approche permet un contrôle avec précision de la nature et de la grammaticalité des candidats à sélectionner. Comme les chunks nominaux, leur sélection est mieux fondée linguistiquement que celle des n-grammes. Hulth (2003), dans ses travaux, sélectionne les termes candidats avec l'aide des patrons des termes-clés de référence qui sont les plus fréquents dans son corpus d’apprentissage (c'est à dire plus de dix occurrences), alors que les autres chercheurs, pour ne citer que Wan et Xiao (2008) et Hasan et Ng (2010), se focalisentent seulement sur les plus longues séquences de noms (noms propres à y inclure) et d’adjectifs.

\smallskip

\textbf{\textit{Exemple :}} les plus longues séquences de noms et d’adjectifs sélectionnées dans la phrase « Une légère brise de côte pourra faiblement rafraichir l’atmosphère » donnent : « légère brise », « côte » et « atmosphère ».